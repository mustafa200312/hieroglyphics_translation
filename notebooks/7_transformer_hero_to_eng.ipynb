{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b5ada30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If sacrebleu is not installed in your environment, uncomment:\n",
    "# !pip -q install sacrebleu tokenizers scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63731150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82e981d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Checkpoint dir: ../best_weights/gardiner_to_english_transformer_checkpoints\n"
     ]
    }
   ],
   "source": [
    "CSV_PATH = \"../Cleaned_data/cleaned_hieroglyphs_data.csv\"\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5\n",
    "LR = 1e-4\n",
    "\n",
    "D_MODEL = 256\n",
    "NHEAD = 8\n",
    "NUM_LAYERS = 3\n",
    "DROPOUT = 0.1\n",
    "MAX_POSITIONS = 4096\n",
    "\n",
    "VOCAB_SIZE_TARGET = 16000  # good default for English\n",
    "\n",
    "CHECKPOINT_DIR = \"../best_weights/gardiner_to_english_transformer_checkpoints\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"Device:\", DEVICE)\n",
    "print(\"Checkpoint dir:\", CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "906a8c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 27654\n",
      "Val size: 3073\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gardiner_sequence</th>\n",
       "      <th>english_translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16381</th>\n",
       "      <td>S19 O1 D21 T22 N35</td>\n",
       "      <td>the siegler peri-sen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26380</th>\n",
       "      <td>A26 S125 G17 D54 G7 W11 G1 V28 Z7 A7A G7 G17 D...</td>\n",
       "      <td>oh 'image of the exhausted' , come to your sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27041</th>\n",
       "      <td>V28 D36 D36 A28 L1 D21 Y1 G17 R15 D58 D46 N25 ...</td>\n",
       "      <td>celebrations reign throughout abydos !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>P6 D36 N35 N35 G81 N35 R8 Q3 N35 M4 X1 3 N11 N...</td>\n",
       "      <td>there this god spent three years and nine mont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16319</th>\n",
       "      <td>F35 D21 X1 N35 X1 G7 X1 X1 Aa1 Q3 Q3 X1 D54 M1...</td>\n",
       "      <td>an offering that the king gives: may he walk p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       gardiner_sequence  \\\n",
       "16381                                 S19 O1 D21 T22 N35   \n",
       "26380  A26 S125 G17 D54 G7 W11 G1 V28 Z7 A7A G7 G17 D...   \n",
       "27041  V28 D36 D36 A28 L1 D21 Y1 G17 R15 D58 D46 N25 ...   \n",
       "1035   P6 D36 N35 N35 G81 N35 R8 Q3 N35 M4 X1 3 N11 N...   \n",
       "16319  F35 D21 X1 N35 X1 G7 X1 X1 Aa1 Q3 Q3 X1 D54 M1...   \n",
       "\n",
       "                                     english_translation  \n",
       "16381                               the siegler peri-sen  \n",
       "26380  oh 'image of the exhausted' , come to your sch...  \n",
       "27041             celebrations reign throughout abydos !  \n",
       "1035   there this god spent three years and nine mont...  \n",
       "16319  an offering that the king gives: may he walk p...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "df = df.dropna(subset=[\"gardiner_sequence\", \"english_translation\"])\n",
    "df[\"gardiner_sequence\"] = df[\"gardiner_sequence\"].astype(str)\n",
    "df[\"english_translation\"] = df[\"english_translation\"].astype(str)\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.10,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Val size:\", len(val_df))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b769bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 16000\n",
      "Special IDs: {'PAD': 0, 'SOS': 1, 'EOS': 2, 'UNK': 3}\n",
      "Saved tokenizer to: ../best_weights/gardiner_to_english_transformer_checkpoints\\tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(BPE(unk_token=\"<unk>\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=VOCAB_SIZE_TARGET,\n",
    "    special_tokens=[\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"]\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(\n",
    "    train_df[\"gardiner_sequence\"].tolist() + train_df[\"english_translation\"].tolist(),\n",
    "    trainer\n",
    ")\n",
    "\n",
    "PAD = tokenizer.token_to_id(\"<pad>\")\n",
    "SOS = tokenizer.token_to_id(\"<sos>\")\n",
    "EOS = tokenizer.token_to_id(\"<eos>\")\n",
    "UNK = tokenizer.token_to_id(\"<unk>\")\n",
    "\n",
    "VOCAB_SIZE = tokenizer.get_vocab_size()\n",
    "\n",
    "print(\"Vocab size:\", VOCAB_SIZE)\n",
    "print(\"Special IDs:\", {\"PAD\": PAD, \"SOS\": SOS, \"EOS\": EOS, \"UNK\": UNK})\n",
    "\n",
    "tokenizer_path = os.path.join(CHECKPOINT_DIR, \"tokenizer.json\")\n",
    "tokenizer.save(tokenizer_path)\n",
    "print(\"Saved tokenizer to:\", tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f04fc312",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, sos_id, eos_id):\n",
    "        self.src = df[\"gardiner_sequence\"].tolist()\n",
    "        self.tgt = df[\"english_translation\"].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sos = sos_id\n",
    "        self.eos = eos_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_ids = [self.sos] + self.tokenizer.encode(self.src[idx]).ids + [self.eos]\n",
    "        tgt_ids = [self.sos] + self.tokenizer.encode(self.tgt[idx]).ids + [self.eos]\n",
    "        return torch.tensor(src_ids, dtype=torch.long), torch.tensor(tgt_ids, dtype=torch.long)\n",
    "\n",
    "\n",
    "def collate_fn(batch, pad_id):\n",
    "    src, tgt = zip(*batch)\n",
    "    src = nn.utils.rnn.pad_sequence(src, batch_first=True, padding_value=pad_id)\n",
    "    tgt = nn.utils.rnn.pad_sequence(tgt, batch_first=True, padding_value=pad_id)\n",
    "    return src, tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bc4b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Seq2SeqDataset(train_df, tokenizer, SOS, EOS)\n",
    "val_ds   = Seq2SeqDataset(val_df, tokenizer, SOS, EOS)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda b: collate_fn(b, PAD)\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=lambda b: collate_fn(b, PAD)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c36e7f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_detok(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Fix common tokenization artifacts produced by BPE/whitespace decoding\n",
    "    so BLEU is computed on normal-looking English text.\n",
    "    \"\"\"\n",
    "    s = s.strip()\n",
    "    s = re.sub(r\"\\s+([.,!?;:])\", r\"\\1\", s)  # \"word .\" -> \"word.\"\n",
    "    s = s.replace(\" n't\", \"n't\").replace(\" '\", \"'\")  # contractions\n",
    "    s = re.sub(r\"\\s+\", \" \", s)  # collapse multiple spaces\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dddc7925",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "\n",
    "        self.register_buffer(\"pe\", pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdc97c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerSeq2Seq(nn.Module):\n",
    "    def __init__(self, vocab_size, pad_id):\n",
    "        super().__init__()\n",
    "        self.pad_id = pad_id\n",
    "\n",
    "        self.src_emb = nn.Embedding(vocab_size, D_MODEL, padding_idx=pad_id)\n",
    "        self.tgt_emb = nn.Embedding(vocab_size, D_MODEL, padding_idx=pad_id)\n",
    "\n",
    "        self.pos_enc = PositionalEncoding(D_MODEL, DROPOUT, MAX_POSITIONS)\n",
    "\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=D_MODEL,\n",
    "            nhead=NHEAD,\n",
    "            num_encoder_layers=NUM_LAYERS,\n",
    "            num_decoder_layers=NUM_LAYERS,\n",
    "            dropout=DROPOUT,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(D_MODEL, vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_pad_mask = (src == self.pad_id)\n",
    "        tgt_pad_mask = (tgt == self.pad_id)\n",
    "\n",
    "        src = self.pos_enc(self.src_emb(src) * math.sqrt(D_MODEL))\n",
    "        tgt = self.pos_enc(self.tgt_emb(tgt) * math.sqrt(D_MODEL))\n",
    "\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size(1)).to(src.device)\n",
    "\n",
    "        out = self.transformer(\n",
    "            src, tgt,\n",
    "            tgt_mask=tgt_mask,\n",
    "            src_key_padding_mask=src_pad_mask,\n",
    "            tgt_key_padding_mask=tgt_pad_mask,\n",
    "            memory_key_padding_mask=src_pad_mask\n",
    "        )\n",
    "\n",
    "        return self.fc_out(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cac570ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for src, tgt in loader:\n",
    "        src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "\n",
    "        # teacher forcing shift\n",
    "        tgt_in = tgt[:, :-1]\n",
    "        tgt_y  = tgt[:, 1:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(src, tgt_in)\n",
    "\n",
    "        loss = criterion(\n",
    "            logits.reshape(-1, VOCAB_SIZE),\n",
    "            tgt_y.reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / max(1, len(loader))\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_loss_acc_and_bleu(model, loader, criterion, pad_id):\n",
    "    \"\"\"\n",
    "    Evaluation is on the loader you pass (we pass val_loader each epoch).\n",
    "    Returns:\n",
    "      - val_loss\n",
    "      - avg_token_acc (micro over all non-pad tokens)\n",
    "      - BLEU (SacreBLEU) on detokenized decoded text\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    all_pred_texts = []\n",
    "    all_gold_texts = []\n",
    "\n",
    "    for src, tgt in loader:\n",
    "        src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "\n",
    "        tgt_in = tgt[:, :-1]\n",
    "        tgt_y  = tgt[:, 1:]\n",
    "\n",
    "        logits = model(src, tgt_in)\n",
    "\n",
    "        loss = criterion(\n",
    "            logits.reshape(-1, VOCAB_SIZE),\n",
    "            tgt_y.reshape(-1)\n",
    "        )\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        preds = logits.argmax(dim=-1)  # (B, T-1)\n",
    "\n",
    "        # avg token accuracy (micro)\n",
    "        mask = (tgt_y != pad_id)\n",
    "        total_correct += (preds[mask] == tgt_y[mask]).sum().item()\n",
    "        total_tokens += mask.sum().item()\n",
    "\n",
    "        # decode for BLEU\n",
    "        preds_np = preds.detach().cpu().numpy()\n",
    "        labels_np = tgt_y.detach().cpu().numpy()\n",
    "\n",
    "        pred_texts = [\n",
    "            simple_detok(tokenizer.decode(list(map(int, ids)), skip_special_tokens=True))\n",
    "            for ids in preds_np\n",
    "        ]\n",
    "        gold_texts = [\n",
    "            simple_detok(tokenizer.decode(list(map(int, ids)), skip_special_tokens=True))\n",
    "            for ids in labels_np\n",
    "        ]\n",
    "\n",
    "        all_pred_texts.extend(pred_texts)\n",
    "        all_gold_texts.extend(gold_texts)\n",
    "\n",
    "    val_loss = total_loss / max(1, len(loader))\n",
    "    avg_token_acc = (total_correct / total_tokens) if total_tokens > 0 else 0.0\n",
    "\n",
    "    bleu = sacrebleu.corpus_bleu(\n",
    "        all_pred_texts,\n",
    "        [all_gold_texts],\n",
    "        force=True\n",
    "    ).score\n",
    "\n",
    "    return val_loss, avg_token_acc, bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "099a3023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n"
     ]
    }
   ],
   "source": [
    "model = TransformerSeq2Seq(VOCAB_SIZE, PAD).to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "print(\"Model initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00273012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(path, model, optimizer, epoch, train_loss, val_loss, avg_token_acc, bleu):\n",
    "    ckpt = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"avg_token_acc\": avg_token_acc,\n",
    "        \"bleu\": bleu,\n",
    "        \"special_ids\": {\"PAD\": PAD, \"SOS\": SOS, \"EOS\": EOS, \"UNK\": UNK},\n",
    "        \"config\": {\n",
    "            \"D_MODEL\": D_MODEL,\n",
    "            \"NHEAD\": NHEAD,\n",
    "            \"NUM_LAYERS\": NUM_LAYERS,\n",
    "            \"DROPOUT\": DROPOUT,\n",
    "            \"VOCAB_SIZE\": VOCAB_SIZE,\n",
    "        }\n",
    "    }\n",
    "    torch.save(ckpt, path)\n",
    "\n",
    "\n",
    "def load_checkpoint(path, model, optimizer=None, map_location=DEVICE):\n",
    "    ckpt = torch.load(path, map_location=map_location)\n",
    "    model.load_state_dict(ckpt[\"model_state\"])\n",
    "    if optimizer is not None and \"optimizer_state\" in ckpt:\n",
    "        optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n",
    "    return ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8e8ad09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\hieroglyphics_project\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "d:\\projects\\hieroglyphics_project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\NestedTensorImpl.cpp:182.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | train_loss=5.1446 | test_loss=4.3733 | avg_token_acc=0.2990 | BLEU=4.40 | epoch_time=2m 2s | elapsed=2m 2s | ETA=8m 10s | saved=../best_weights/gardiner_to_english_transformer_checkpoints\\epoch_001.pt\n",
      "Epoch 2/5 | train_loss=4.1694 | test_loss=3.9491 | avg_token_acc=0.3380 | BLEU=6.87 | epoch_time=2m 5s | elapsed=4m 8s | ETA=6m 11s | saved=../best_weights/gardiner_to_english_transformer_checkpoints\\epoch_002.pt\n",
      "Epoch 3/5 | train_loss=3.7836 | test_loss=3.6826 | avg_token_acc=0.3679 | BLEU=5.40 | epoch_time=2m 59s | elapsed=7m 8s | ETA=4m 44s | saved=../best_weights/gardiner_to_english_transformer_checkpoints\\epoch_003.pt\n",
      "Epoch 4/5 | train_loss=3.5182 | test_loss=3.5107 | avg_token_acc=0.3894 | BLEU=7.23 | epoch_time=2m 58s | elapsed=10m 8s | ETA=2m 31s | saved=../best_weights/gardiner_to_english_transformer_checkpoints\\epoch_004.pt\n",
      "Epoch 5/5 | train_loss=3.3101 | test_loss=3.3788 | avg_token_acc=0.4034 | BLEU=8.78 | epoch_time=2m 25s | elapsed=12m 34s | ETA=0s | saved=../best_weights/gardiner_to_english_transformer_checkpoints\\epoch_005.pt\n",
      "\n",
      "Training finished.\n",
      "Best checkpoint: ../best_weights/gardiner_to_english_transformer_checkpoints\\best.pt\n",
      "Best validation (test) loss: 3.378822634257183\n"
     ]
    }
   ],
   "source": [
    "def fmt(sec):\n",
    "    sec = int(sec)\n",
    "    h = sec // 3600\n",
    "    m = (sec % 3600) // 60\n",
    "    s = sec % 60\n",
    "    if h > 0:\n",
    "        return f\"{h}h {m}m {s}s\"\n",
    "    if m > 0:\n",
    "        return f\"{m}m {s}s\"\n",
    "    return f\"{s}s\"\n",
    "\n",
    "\n",
    "# ---- Lists to store losses and metrics per epoch ----\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_token_accs = []\n",
    "val_bleus = []\n",
    "\n",
    "start_all = time.time()\n",
    "epoch_times = []\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_path = os.path.join(CHECKPOINT_DIR, \"best.pt\")\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    start_epoch = time.time()\n",
    "\n",
    "    # ---- TRAIN ----\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # ---- VALIDATION / TEST ----\n",
    "    val_loss, avg_token_acc, bleu = eval_loss_acc_and_bleu(\n",
    "        model, val_loader, criterion, PAD\n",
    "    )\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "    val_token_accs.append(avg_token_acc)\n",
    "    val_bleus.append(bleu)\n",
    "\n",
    "    # ---- Timing ----\n",
    "    epoch_sec = time.time() - start_epoch\n",
    "    epoch_times.append(epoch_sec)\n",
    "\n",
    "    elapsed_sec = time.time() - start_all\n",
    "    avg_epoch_sec = sum(epoch_times) / len(epoch_times)\n",
    "    eta_sec = (EPOCHS - epoch) * avg_epoch_sec\n",
    "\n",
    "    # ---- Save checkpoint ----\n",
    "    ckpt_path = os.path.join(CHECKPOINT_DIR, f\"epoch_{epoch:03d}.pt\")\n",
    "    save_checkpoint(\n",
    "        ckpt_path,\n",
    "        model,\n",
    "        optimizer,\n",
    "        epoch,\n",
    "        train_loss,\n",
    "        val_loss,\n",
    "        avg_token_acc,\n",
    "        bleu\n",
    "    )\n",
    "\n",
    "    # ---- Save best model (by validation loss) ----\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        save_checkpoint(\n",
    "            best_path,\n",
    "            model,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            train_loss,\n",
    "            val_loss,\n",
    "            avg_token_acc,\n",
    "            bleu\n",
    "        )\n",
    "\n",
    "    # ---- PRINT (train + test/val loss explicitly) ----\n",
    "    print(\n",
    "        f\"Epoch {epoch}/{EPOCHS} | \"\n",
    "        f\"train_loss={train_loss:.4f} | \"\n",
    "        f\"test_loss={val_loss:.4f} | \"\n",
    "        f\"avg_token_acc={avg_token_acc:.4f} | \"\n",
    "        f\"BLEU={bleu:.2f} | \"\n",
    "        f\"epoch_time={fmt(epoch_sec)} | \"\n",
    "        f\"elapsed={fmt(elapsed_sec)} | \"\n",
    "        f\"ETA={fmt(eta_sec)} | \"\n",
    "        f\"saved={ckpt_path}\"\n",
    "    )\n",
    "\n",
    "print(\"\\nTraining finished.\")\n",
    "print(\"Best checkpoint:\", best_path)\n",
    "print(\"Best validation (test) loss:\", best_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c40870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# ckpt = load_checkpoint(os.path.join(CHECKPOINT_DIR, \"best.pt\"), model, optimizer)\n",
    "# print(\"Resumed from epoch:\", ckpt[\"epoch\"], \"val_loss:\", ckpt[\"val_loss\"], \"BLEU:\", ckpt[\"bleu\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
